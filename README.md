# Visual_Question_Answering
# Image-based Question Answering System

This project is a deep learning-based application that takes an image and a question as input and generates a relevant answer based on the image content. It demonstrates the use of vision-language models for Visual Question Answering (VQA).



https://github.com/user-attachments/assets/87a776c4-955e-496f-b49a-83ed95e659cc



![image](https://github.com/user-attachments/assets/cda87acd-9b13-4026-bca0-1fb3f43f729e)

## ğŸš€ Features

- Upload an image and ask a question about it.
- Get accurate answers using a pre-trained vision-language model.
- Interactive UI using Streamlit.
- Uses the BLIP (Bootstrapping Language-Image Pretraining) model from Hugging Face.

## ğŸ› ï¸ Tech Stack

- **Language**: Python
- **Framework**: Streamlit
- **Models**: Salesforce BLIP-VQA Base (Hugging Face)
- **Libraries**: `torch`, `transformers`, `PIL`, `requests`, `streamlit`
